{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d24fb56-e617-4aef-873b-470d074b0d3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scraping dynamic web sites with Selenium\n",
    "\n",
    "[Last week's lesson](../pt1/scraping_lecture.ipynb) involved scraping a static site, or a site that is rendered up front in HTML. Today, we'll look at how to scrape sites that change when you load or interact with the page, sometimes without the URL changing.\n",
    "\n",
    "[Selenium](https://www.selenium.dev/documentation/) was created to \"automate browsers.\" The major use case for software like Selenium is to automate testing browser-based apps. But journalists can use software like Selenium to scrape dynamic websites.\n",
    "\n",
    "For today's lesson, we're going to scrape all the public hearings in Alameda County courts on a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3480489-09ab-4566-ad48-d26769bd20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ad8f2-f2c4-4e0c-831e-89abd8c58624",
   "metadata": {},
   "source": [
    "## Open your automated browser\n",
    "\n",
    "Earlier we installed `chromedriver` using `brew`. Below, we tell Selenium to use Chrome as our automated browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b419ae7-3260-495b-8c91-e955989f5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# some people like to call this variable `browser` — call it whatever you like!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8022c51-3ebd-42e3-b16c-bd6f7415b139",
   "metadata": {},
   "source": [
    "## Open the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d44ee5-6be6-4c5a-8810-8f2ffaaab3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to a URL\n",
    "driver.get('https://publicrecords.alameda.courts.ca.gov/CalendarSearch/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f2027-925b-48ba-ab46-d1c2f5131082",
   "metadata": {},
   "source": [
    "## Find the inputs you want to interact with\n",
    "\n",
    "In last week's lecture, we used Beautiful Soup to find elements on a page. Because we want to interact with elements within Selenium's automated browser, we need to use Selenium to find elements. \n",
    "\n",
    "Tips:\n",
    "- If you want to interact with the page, use selenium\n",
    "- If you want to read or parse complex HTML, use bs4\n",
    "\n",
    "You'll use `By` to indicate how the browser will pinpoint your element. These are the [different options for `By`](https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.by.html):\n",
    "\n",
    "- `CLASS_NAME`\n",
    "- `CSS_SELECTOR` (e.g. a pseudo-element)\n",
    "- `ID`\n",
    "- `LINK_TEXT` (the text inside <a> tags)\n",
    "- `NAME`\n",
    "- `PARTIAL_LINK_TEXT` (the text inside <a> tags)\n",
    "- `TAG_NAME`\n",
    "- `XPATH` (when the element doesn't have a unique identifer, you can still pinpoint with this method; Chrome has a cool way to grab the xpath of an item in Developer Tools)\n",
    "\n",
    "Luckily, the date fields have IDs, so we can select them this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96297862-07a0-41c7-ae7d-e8da85812b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hearing_date_from = driver.find_element(By.ID, 'FeaturedContent_txtFromdt')\n",
    "hearing_date_to   = driver.find_element(By.ID, 'FeaturedContent_txtTodt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc2a5b-1ff9-48a4-9f52-538c1fcf715f",
   "metadata": {},
   "source": [
    "You can use `type()` to find out whether a variable is a selenium object or a bs4 object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e6918-d542-4484-883c-e9dbe47d2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hearing_date_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d790d0e-95d9-467e-8dbf-b7fef5410023",
   "metadata": {},
   "source": [
    "## Input dates into the dropdowns\n",
    "\n",
    "Use selenium's `send_keys()` method to input text into the date dropdowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addde64-403f-4600-8852-8fe902f7dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hearing_date_from.send_keys('12/06/2021')\n",
    "hearing_date_to.send_keys('12/06/2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c726b-d004-40ef-b4c6-b64a04916fe6",
   "metadata": {},
   "source": [
    "## \"Click\" on the submit button\n",
    "\n",
    "First, you'll have to find the element by its `id` value, then `click()` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba8544-cb94-4e3f-9bad-9e208fde2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_button = driver.find_element(By.ID, 'FeaturedContent_btFind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f698a3-fef1-4179-bf13-14dfbf6425f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e95347-add9-41af-a5cf-080511c26b20",
   "metadata": {},
   "source": [
    "Below, I'm telling the computer to wait 5 seconds before executing the next line of code. That way the browser can finish loading the page before continuing with the code. That's crucial if I end up restarting this notebook kernel and running all cells at once. We want the browser to finish loading the page because some elements might not exist until the element exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca4916-42d2-4485-8a10-64bd11ce80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5801390-12ac-4183-bb4f-b2435809f9fb",
   "metadata": {},
   "source": [
    "There are better ways to wait for elements on a page. Check out the documentation to read more about [WebDriverWait()](https://selenium-python.readthedocs.io/waits.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc2e2a-63e3-40b0-86f1-5372fe067b43",
   "metadata": {},
   "source": [
    "## \"Select\" more rows to view\n",
    "\n",
    "When you  get your search results, the courts show only 10 rows at a time. It'll be faster to scrape all the results if you can show the max amount of rows at a time (which is 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b8b37-6bc6-4ac2-bf1e-0e993eed01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_rows_dropdown = Select(driver.find_element(By.NAME, 'ctl00$MainContent$gvResult$ctl13$ctl13'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ab44f-97d6-4800-a5f4-2223fdd04ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_rows_dropdown.select_by_visible_text('50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada65fef-2473-4193-a1c2-2bc2a9dd3e54",
   "metadata": {},
   "source": [
    "## Get the count of results so you know how many pages you have to scrape\n",
    "\n",
    "Even though I'm parsing HTML below, I'm using Selenium instead of Beautiful Soup. I'm doing this because I haven't called Beautiful Soup yet and Selenium is capable of parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27dffa-93cf-4188-8dd9-2736fc0f62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_count_container = driver.find_element(By.ID, 'MainContent_lbCnt')\n",
    "records_count = records_count_container.text.split()\n",
    "records_count = records_count[len(records_count) - 1]\n",
    "records_count = int(records_count)\n",
    "records_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c322cf-5741-420e-a757-f9485a6facf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_check = math.ceil(records_count/50)\n",
    "pages_to_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1ea78-2afb-4f2e-abea-907aec07d699",
   "metadata": {},
   "source": [
    "## Figure out how to loop through the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada0c2d-e18a-4669-ad16-598b20e3c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the \"Next\" link — it looks like \">\"\n",
    "next_button = driver.find_element(By.LINK_TEXT, '>')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba0039-ac3e-42e9-ae04-6887f3a1ddb2",
   "metadata": {},
   "source": [
    "The below code is commented out because I don't want you to run it yet. But, you can see how one could flip through all the pages of this site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5412010b-5e02-4647-8795-01f837c3eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(pages_to_check):\n",
    "#     next_button = driver.find_element(By.LINK_TEXT, '>')\n",
    "#     next_button.click()\n",
    "    \n",
    "#     # wait 2 seconds\n",
    "#     time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3a7a8-832b-4344-9ed4-ef49cd21eff2",
   "metadata": {},
   "source": [
    "You can manually get back to the first page by going to the \"automated\" browser and clicking \"1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03253d14-6b6b-4644-99a5-a0b2348a8450",
   "metadata": {},
   "source": [
    "## Parse the first page of results with Beautiful Soup\n",
    "\n",
    "Now I'm going to switch to using Beautiful Soup because it's the best program to parse through a lot of HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64547ad-1518-4a28-bd85-14297bf371be",
   "metadata": {},
   "source": [
    "### Get the table by its `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b35a1b-9c09-4044-9df4-50609a5928db",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "table = soup.find(id='MainContent_gvResult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43801039-715c-4829-9e93-128c46731de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05025cc7-7bfb-465d-83c7-856a4386b4f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Each row of this table is a unique something. I'm not sure what that something is. It might not be a unique case. It might be something else. I'm not going to assume. Anyway, I'd like to transfer this table into a pandas dataframe.\n",
    "\n",
    "### Create your blank dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692906ba-4160-44e5-b8af-b1916dc006f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hearings = pd.DataFrame(\n",
    "    columns=[\n",
    "        'Serial No.',\n",
    "        'Name',\n",
    "        'Case #',\n",
    "        'PFN',\n",
    "        'CEN',\n",
    "        'Dept#',\n",
    "        'Hearing Date',\n",
    "        'Hearing Time',\n",
    "        'Hearing Type',\n",
    "        'Case Type',\n",
    "        'Defense Atty',\n",
    "        'DA'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4aba77-4402-4018-8bf0-ae297d2d37eb",
   "metadata": {},
   "source": [
    "### Parse the table and put the data into a dataframe\n",
    "\n",
    "Let's go over each section below manually before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad675020-0433-4c00-8f15-ca3531a8da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple `page_data` list to store the page data before we make a pandas dataframe\n",
    "page_data = []\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# we haven't used enumerate() yet but basically that just allows you to index an iterable\n",
    "for i, row in enumerate(rows):\n",
    "\n",
    "    # we can skip the first row because that's the header row\n",
    "    # we can also skip any row greater than index 50 because that has the page numbers\n",
    "    if (i > 0) and (i <= 50):\n",
    "    \n",
    "        # `cells` will get and index all the cells within a row\n",
    "        cells = row.find_all('td')\n",
    "        page_data.append({\n",
    "            'Serial No.' : cells[0].text.strip(),\n",
    "            'Name' : cells[1].text.strip(), \n",
    "            'Case #' : cells[2].text.strip(), \n",
    "            'PFN' : cells[3].text.strip(), \n",
    "            'CEN' : cells[4].text.strip(), \n",
    "            'Dept#' : cells[5].text.strip(), \n",
    "            'Hearing Date' : cells[6].text.strip(), \n",
    "            'Hearing Time' : cells[7].text.strip(), \n",
    "            'Hearing Type' : cells[8].text.strip(), \n",
    "            'Case Type' : cells[9].text.strip(), \n",
    "            'Defense Atty' : cells[10].text.strip(), \n",
    "            'DA' : cells[11].text.strip()\n",
    "        })\n",
    "        \n",
    "# create a dataframe with `page_data`\n",
    "page_hearing = pd.DataFrame(page_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39398ae2-8d67-4be4-a092-7a307d206ad1",
   "metadata": {},
   "source": [
    "## Append `page_hearing` dataframe to main `hearings` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b90c8c-739a-471f-95b5-f810382c427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hearings = hearings.append(page_hearing).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da8289-a802-480f-9f87-a7417bb81864",
   "metadata": {},
   "source": [
    "## View dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fdbf2-dabe-4acb-bfcb-9b7ad95846af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hearings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02c85b-06f4-4975-add7-e0382f256209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(pages_to_check):\n",
    "#     next_button = driver.find_element(By.LINK_TEXT, '>')\n",
    "#     next_button.click()\n",
    "#     time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2f758-4cf9-42d8-ab4b-417a61373bd4",
   "metadata": {},
   "source": [
    "## Addenda \n",
    "\n",
    "If I want to search for another date, I can stay on the same page and \"clear\" the date fields. Then I send send new dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d6329-677a-4abd-874a-04e8f1187cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hearing_date_from.clear()\n",
    "hearing_date_to.clear()\n",
    "\n",
    "hearing_date_from.send_keys('12/07/2021')\n",
    "hearing_date_to.send_keys('12/07/2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05122477-0e31-466d-a6ad-ec14ade8dbf8",
   "metadata": {},
   "source": [
    "Once you're done using the automated browser, you can close it manually or run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e7b25-d0a3-43a6-9996-c962ae65cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc32ab-0016-4f96-acf3-ce7c621eb64d",
   "metadata": {},
   "source": [
    "## Classwork\n",
    "\n",
    "I'd like you to figure out how to loop through all the pages and collect all the information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
